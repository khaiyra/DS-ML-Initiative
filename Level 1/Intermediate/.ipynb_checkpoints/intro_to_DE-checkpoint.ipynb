{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LEVEL 1: Introduction to Data Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Understand what Data Engineering Entails\n",
    "* Understand the requirements \n",
    "* Understand the essential tools and what they are used for.\n",
    "\n",
    "Take Course and answer a few questions\n",
    "- Course:  Datacamp data Engineering\n",
    "\n",
    "Questions:\n",
    "        Answer all the questions in your own words and best suitable terms\n",
    "1. In your own words what are the difference between Data Engineering and Data Science\n",
    "2. Why do you prefer Data Engineering\n",
    "3. Name the important tools required to learn Data Engineering and how familiar you are with each ( Novice , Amateur, Fair, Good).\n",
    "4. Draw a flowchart for a typical ETL Pipeline.\n",
    "5. Whats are the differences between the following: \n",
    "(briefly describe and give difference).\n",
    "- ETL Pipeline and ELT Pipeline\n",
    "- Data Warehouses and Data Lakes\n",
    "\n",
    "Goodluck!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "Data engineering is a branch of data science that focuses on designing, building and maintaining data pipelines that collects data from different sources, extracts, transform and loads the data to be used for further analysis.\n",
    "\n",
    "Data science is a field that extracts insights, build and train predictive models from structured or unstructured data across broad range of application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "For someone who loves to work with data both structured and non stuctured,  data engineering allows to design, manage and optimize the flow of these data for easy access and use by a data analyst or scientist. I prefer Data engineering as it is the foundation for a successful data-driven company which also encompasses untapped market of opportunities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "The important tools required to learn data engineering are as follows:\n",
    "\n",
    "* programming languages\n",
    "<ul> Python (good) </ul>\n",
    "<ul> Java (amateur) </ul>\n",
    "* Databases \n",
    "<ul> MySQL (good) </ul>\n",
    "<ul> NoSQL (amateur) </ul>\n",
    "* Orchestration \n",
    "<ul> Airflow (amateur) </ul>\n",
    "* Cloud platforms \n",
    "<ul> AWS (amateur) </ul>\n",
    "<ul> GCP (amateur) </ul>\n",
    "<ul> Azure (amateur) </ul>\n",
    "* Pipeline \n",
    "<ul> Kafka (amateur) </ul>\n",
    "<ul> Spark (amateur) </ul>\n",
    "* Visualization \n",
    "<ul> PowerBI (good) </ul>\n",
    "<ul> Data studio (novice) </ul>\n",
    "* Testing \n",
    "<ul> Pytest (fair) </ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "Flowchart for a typical ETL pipeline\n",
    "\n",
    "#**** image here *****#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "* #### Differences between ETL pipeline and ELT pipeline:\n",
    "ETL(extract-transform-load) is a common data engineering pipeline from one or multiple data sources, merged, transformed and converted and then load to a final data store. The data store is generally referred to as a database but may be a data warehouse, data mart, data lake or any other system where the resulting data can be efficiently queried. Meanwhile, ELT(extract-load-transform) pipeline brings all source data into a central data store, and then performs a set of simple transforms keeping the result at each stage until a final data model is achieved. It allows additional data models to be easily added.\n",
    "\n",
    "* #### Differences between Data warehouses and Data Lakes:\n",
    "Data warehouses is a store house for data that is already structured, filtered and has been processed for a specific purpose while data lakea is a large set of raw data, which supports any data type and does not yet have a defined purpose. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
